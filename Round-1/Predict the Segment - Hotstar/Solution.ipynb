{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_json('train.json', orient='index')\n",
    "test_data = pd.read_json('test.json', orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data.reset_index(level=0, inplace=True)\n",
    "train_data.rename(columns={'segment':'target', 'index':'ID'}, inplace=True)\n",
    "train_data.replace({'target':{'neg':0,'pos':1}}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_data.reset_index(level=0, inplace=True)\n",
    "test_data.rename(columns={'index':'ID'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieving Genre Names & Creating columns for Each genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data['genre_list']=[re.sub(pattern='\\:\\d+', repl='', string=x) for x in train_data['genres']]\n",
    "train_data['genre_list']=train_data['genre_list'].apply(lambda x: x.split(',')) \n",
    "#[x.split(',') for x in train_data['genre_list']]- It will work in same manner only diff is it returns list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_data['genre_list'] = [re.sub(pattern='\\:\\d+', repl='', string=x) for x in test_data['genres'] ]\n",
    "test_data['genre_list'] = test_data['genre_list'].apply(lambda x: x.split(','))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k=train_data['genre_list'].apply(frozenset)  #Frozensets of genre for each row\n",
    "t1 = frozenset.union(*k)                     #set of genres(union of frozen sets)\n",
    "for i in t1:\n",
    "    train_data[i] = train_data['genre_list'].apply(lambda x: int(i in x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k=test_data['genre_list'].apply(frozenset)  #Frozensets of genre for each row\n",
    "t2 = frozenset.union(*k)                    #set of genres(union of frozen sets)\n",
    "for i in t2:\n",
    "    test_data[i] = test_data['genre_list'].apply(lambda x: int(i in x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieving DOW & Creating columns for Each DOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data['dow_list'] = [re.sub(pattern='\\:\\d+', repl='', string=x) for x in train_data['dow']]\n",
    "train_data['dow_list'] = train_data['dow_list'].apply(lambda x: x.split(','))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_data['dow_list'] = [re.sub(pattern='\\:\\d+', repl='', string=x) for x in test_data['dow']]\n",
    "test_data['dow_list'] = test_data['dow_list'].apply(lambda x: x.split(','))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k = train_data['dow_list'].apply(frozenset)\n",
    "t1 = frozenset.union(*k)\n",
    "\n",
    "for i in t1:\n",
    "    col='dow'+str(i)\n",
    "    train_data[col] = train_data['dow_list'].apply(lambda x: int(i in x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k = test_data['dow_list'].apply(frozenset)\n",
    "t2 = frozenset.union(*k)\n",
    "\n",
    "for i in t2:\n",
    "    col='dow'+str(i)\n",
    "    test_data[col] = test_data['dow_list'].apply(lambda x: int(i in x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieving City Names & Creating columns for Each city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data['city_list'] = [re.sub(pattern='\\:\\d+', repl='', string=x) for x in train_data['cities']]\n",
    "train_data['city_list'] = train_data['city_list'].apply(lambda x: x.split(','))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_data['city_list'] = [re.sub(pattern='\\:\\d+', repl='', string=x) for x in test_data['cities']]\n",
    "test_data['city_list'] = test_data['city_list'].apply(lambda x: x.split(','))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieving TOD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data['tod_list'] = [re.sub(pattern='\\:\\d+', repl='', string=x) for x in train_data['tod']]\n",
    "train_data['tod_list'] = train_data['tod_list'].apply(lambda x:x.split(','))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_data['tod_list'] = [re.sub(pattern='\\:\\d+', repl='', string=x) for x in test_data['tod']]\n",
    "test_data['tod_list'] = test_data['tod_list'].apply(lambda x: x.split(','))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k = train_data['tod_list'].apply(frozenset)\n",
    "t1 = frozenset.union(*k)\n",
    "for i in t1:\n",
    "    col='tod'+str(i)\n",
    "    train_data[col] = train_data['tod_list'].apply(lambda x: int(i in x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k = test_data['tod_list'].apply(frozenset)\n",
    "t2 = frozenset.union(*k)\n",
    "for i in t2:\n",
    "    col = 'tod'+str(i)\n",
    "    test_data[col] = test_data['tod_list'].apply(lambda x: int(i in x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating Total time for each row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t1=[]\n",
    "for i in np.arange(train_data.shape[0]):\n",
    "    a=np.sum(pd.Series(re.sub(pattern='.*\\:', repl='', string=x) for x in (train_data['cities'][i].split(','))).apply(int))\n",
    "    t1.append(a)\n",
    "\n",
    "train_data['total_time']=t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t1=[]\n",
    "for i in np.arange(test_data.shape[0]):\n",
    "    a=np.sum(pd.Series(re.sub(pattern='.*\\:', repl='', string=x) for x in (test_data['cities'][i].split(','))).apply(int))\n",
    "    t1.append(a)\n",
    "\n",
    "test_data['total_time']=t1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Counting Number of titles, genres etc, for each row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def wcount(p):\n",
    "    return (p.count(',')+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data['title_count'] = train_data['titles'].map(wcount)\n",
    "train_data['genre_count'] = train_data['genres'].map(wcount)\n",
    "train_data['city_count'] = train_data['cities'].map(wcount)\n",
    "train_data['tod_count'] = train_data['tod'].map(wcount)\n",
    "train_data['dow_count'] = train_data['dow'].map(wcount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_data['title_count'] = test_data['titles'].map(wcount)\n",
    "test_data['genre_count'] = test_data['genres'].map(wcount)\n",
    "test_data['city_count'] = test_data['cities'].map(wcount)\n",
    "test_data['tod_count'] = test_data['tod'].map(wcount)\n",
    "test_data['dow_count'] = test_data['dow'].map(wcount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "drop_col = ['ID','cities','dow', 'genres', 'titles', 'tod', 'genre_list', 'dow_list', 'city_list', 'tod_list', 'NA'] ## NA\n",
    "train = train_data.drop(labels=drop_col, axis=1)\n",
    "test = test_data.drop(labels=drop_col, axis=1)\n",
    "label = train['target']\n",
    "train.drop(labels=['target'], inplace=True, axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = xgb.XGBClassifier(learning_rate=0.05, max_depth=5, min_child_weight=5, gamma=0.5, reg_lambda=8)\n",
    "kfold = KFold(n_splits=3, random_state=2017)\n",
    "grid_params = {'n_estimators':[400,450,500,550], 'colsample_bylevel':[0.5,0.4,0.3,0.2], 'subsample':[0.7,0.6,0.5,0.4]  }\n",
    "grid1 = GridSearchCV(estimator=model,param_grid=grid_params, scoring='roc_auc', cv=kfold, n_jobs=-1)\n",
    "grid1.fit(train, label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print grid1.best_estimator_\n",
    "print grid1.best_params_\n",
    "print grid1.best_score_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(n_estimators=200, max_depth=5, )\n",
    "kfold = KFold(n_splits=3, random_state=7)\n",
    "results = cross_val_score(model,train,label,cv=kfold,scoring='roc_auc',n_jobs=-1)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(n_estimators=1500, max_depth=8 )\n",
    "model.fit(train,label);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prediction = model.predict_proba(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prediction = prediction[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainX, valX, train_l, val_l = train_test_split(train,label, test_size=0.4, random_state=2017)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds = train.columns\n",
    "DMtrain_all = xgb.DMatrix(train, label, feature_names=preds)\n",
    "DMtrain = xgb.DMatrix(trainX, train_l, feature_names=preds)\n",
    "DMval = xgb.DMatrix(valX, val_l, feature_names=preds)\n",
    "DMtest = xgb.DMatrix(test, feature_names=preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xgb_params={\n",
    "    'eta':0.05,\n",
    "    'max_depth':5,\n",
    "    'colsample_bytree':1.0,\n",
    "    'colsample_bylevel':0.3,\n",
    "    'subsample':0.6,\n",
    "    'objective':'binary:logistic',\n",
    "    'eval_metric':'auc',\n",
    "    'min_child_weight':5,\n",
    "    'silent':1,\n",
    "    'seed':2017,\n",
    "    'nthread':4,\n",
    "    'gamma':0.4,\n",
    "    'lambda':8\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "watchlist = [(DMtrain, 'Train'), (DMval, 'Validation')]\n",
    "num_rounds = 2000\n",
    "model = xgb.train(xgb_params, DMtrain, num_rounds, watchlist, early_stopping_rounds=50,verbose_eval=5)\n",
    "              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = xgb.train(xgb_params, DMtrain_all, num_boost_round=int(410))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prediction = model.predict(DMtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub_file = pd.read_csv('sample_submission.csv')\n",
    "sub_file['ID'] = test_data['ID']\n",
    "sub_file['segment'] = prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub_file.to_csv('subm_file1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
